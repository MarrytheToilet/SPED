"""
ä¸Šä¼ æ¨¡å— - æ‰¹é‡ä¸Šä¼ PDFæ–‡ä»¶åˆ°MinerU API
"""
import os
import sys
import csv
import requests
from glob import glob
from math import ceil
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from settings import (
    MINERU_API_BASE as API_BASE,
    MINERU_HEADERS as HEADERS,
    MINERU_WEB_BASE as WEB_BASE,
    PDF_DIR,
    BATCH_CSV,
    BATCH_SIZE,
    UPLOAD_CONFIG,
    FILE_CONFIG
)

def upload_batch(batch_files, batch_index):
    """
    ä¸Šä¼ ä¸€æ‰¹PDFæ–‡ä»¶
    
    Args:
        batch_files: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        batch_index: æ‰¹æ¬¡ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
    
    Returns:
        batch_id: æ‰¹æ¬¡IDï¼Œå¤±è´¥è¿”å›None
    """
    print(f"\nğŸš€ å¼€å§‹ä¸Šä¼ ç¬¬ {batch_index+1} æ‰¹ï¼Œå…± {len(batch_files)} ä¸ªæ–‡ä»¶")

    # 1ï¸âƒ£ ç”³è¯·ä¸Šä¼ URL
    files_data = []
    for idx, pdf in enumerate(batch_files):
        filename = os.path.basename(pdf)
        base_name = os.path.splitext(filename)[0]
        
        # é™åˆ¶data_idé•¿åº¦ï¼Œé¿å…è¶…è¿‡128å­—ç¬¦
        if len(base_name) > 60:
            base_name = base_name[:60]
        
        data_id = f"b{batch_index+1}_{idx+1}_{base_name}"
        
        files_data.append({
            "name": filename,
            "data_id": data_id,
            **FILE_CONFIG
        })

    response = requests.post(
        f"{API_BASE}/file-urls/batch",
        headers=HEADERS,
        json={
            **UPLOAD_CONFIG,
            "files": files_data,
        },
    )

    if response.status_code != 200:
        print(f"âŒ ç”³è¯·ä¸Šä¼ URLå¤±è´¥ï¼šHTTP {response.status_code}")
        print(response.text)
        return None

    result = response.json()
    if result.get("code") != 0:
        print(f"âŒ ç”³è¯·å¤±è´¥ï¼š{result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
        return None

    batch_id = result["data"]["batch_id"]
    urls = result["data"]["file_urls"]

    # 2ï¸âƒ£ ä¸Šä¼ æ–‡ä»¶
    success = 0
    for pdf_path, upload_url in zip(batch_files, urls):
        with open(pdf_path, "rb") as f:
            res = requests.put(upload_url, data=f)
            if res.status_code in [200, 201]:
                success += 1
                print(f"âœ… æˆåŠŸä¸Šä¼ ï¼š{os.path.basename(pdf_path)}")
            else:
                print(f"âŒ ä¸Šä¼ å¤±è´¥ï¼š{os.path.basename(pdf_path)} | çŠ¶æ€ç ï¼š{res.status_code}")

    # 3ï¸âƒ£ æ‰“å° & ä¿å­˜ç»“æœ
    print(f"ğŸ¯ æ‰¹æ¬¡å®Œæˆï¼šæˆåŠŸ {success}/{len(batch_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“¦ æ‰¹æ¬¡ IDï¼š{batch_id}")
    access_url = f"{WEB_BASE}/{batch_id}"
    print(f"ğŸ”— è®¿é—®åœ°å€ï¼š{access_url}\n")

    # âœ… è¿½åŠ ä¿å­˜åˆ° CSV
    os.makedirs(os.path.dirname(BATCH_CSV), exist_ok=True)
    with open(BATCH_CSV, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([batch_index + 1, batch_id, len(batch_files), access_url])

    return batch_id


def main():
    """ä¸»å‡½æ•° - æ‰¹é‡ä¸Šä¼ PDFæ–‡ä»¶"""
    pdf_files = glob(str(PDF_DIR / "*.pdf"))
    if not pdf_files:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° PDF æ–‡ä»¶ï¼š{PDF_DIR}")
        return

    total_batches = ceil(len(pdf_files) / BATCH_SIZE)
    print(f"å…±å‘ç° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶ï¼Œå°†åˆ†æˆ {total_batches} æ‰¹ä¸Šä¼ ã€‚")

    # åˆå§‹åŒ– CSV
    if not os.path.exists(BATCH_CSV):
        with open(BATCH_CSV, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["batch_index", "batch_id", "file_count", "access_url"])

    all_batches = []
    for i in range(total_batches):
        start = i * BATCH_SIZE
        end = start + BATCH_SIZE
        batch_files = pdf_files[start:end]
        batch_id = upload_batch(batch_files, i)
        if batch_id:
            all_batches.append(batch_id)

    print("\nâœ… æ‰€æœ‰æ‰¹æ¬¡ä¸Šä¼ å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³ï¼šupload_batches.csv")
    for b in all_batches:
        print(f"ğŸ“¦ æ‰¹æ¬¡IDï¼š{b} | è®¿é—®é“¾æ¥ï¼š{WEB_BASE}/{b}")


if __name__ == "__main__":
    main()
