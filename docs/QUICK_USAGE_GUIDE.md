# 快速使用指南

## 🚀 立即开始

### 1. 测试系统
```bash
python extract.py test
```
输出示例：
```
✅ OPENAI_API_KEY: 已配置
✅ 找到 125 篇已解析论文
✅ API连接成功
✅ 系统测试通过！
```

### 2. 提取单篇论文
```bash
python extract.py single
```
然后从列表中选择论文编号。

### 3. 批量提取所有论文
```bash
python extract.py batch
```

## 📋 提取结果示例

**输入**: 人工关节论文PDF（已通过MinerU解析为full.md）

**输出**: JSON格式的结构化数据
```json
{
  "dataid": "AJ_20251103_4026ca86",
  "paper_id": "论文标题",
  "records": [
    {
      "数据标识": "CoCrMo-UHMWPE髋关节摩擦磨损实验",
      "应用部位": "髋关节",
      "球头信息.球头基本信息": "{\"材料类别\": \"CoCrMo合金\", \"直径\": \"28 mm\"}",
      "球头信息.球头-成分组成": "{\"Co\": \"60.5 wt%\", \"Cr\": \"28.0 wt%\"}",
      "体外实验-内衬与球头摩擦腐蚀实验.内衬与球头-实验设置": "{\"载荷\": \"50 N\", \"温度\": \"37°C\"}",
      ...全部28个字段...
    }
  ],
  "count": 9
}
```

## 🎯 提取质量

基于真实论文测试：
- ✅ **准确性**: LLM严格按照prompt提取，不编造数据
- ✅ **完整性**: 所有28个字段都出现（未提及的为null）
- ✅ **格式**: 100%符合JSON schema
- ✅ **智能合并**: 自动判断创建新记录还是完善已有记录
- ✅ **平均字段数**: 8-10个非空字段/记录

## ⚙️ 配置优化

### 使用更强大的模型
```bash
# .env 文件
OPENAI_MODEL=gpt-4o  # 推荐！更准确
```

### 增加上下文以提高质量
```bash
# .env 文件
CHUNK_SIZE=15000     # 增大chunk（默认10000）
CHUNK_OVERLAP=500    # 增大重叠（默认300）
```

### 加速提取
```bash
# .env 文件
OPENAI_MODEL=gpt-4o-mini  # 更快但略少准确
CHUNK_SIZE=8000           # 减小chunk
```

## 📂 目录结构

```
sped/
├── data/
│   └── processed/
│       ├── parsed/          # 输入：解析后的论文（full.md）
│       └── extracted/       # 输出：提取的JSON数据
├── prompts/
│   └── prompt.md           # 提取prompt（包含详细示例）
├── src/
│   └── agents/
│       └── llm_agent.py    # LLM提取逻辑
└── extract.py              # 主程序
```

## 🔍 查看提取日志

提取过程中会显示详细日志：
```
[LLM提取Agent] 处理 Chunk 4/12
[LLM提取Agent]   ✓ 提取到 3 条记录
[LLM提取Agent]     + 新增记录: CoCrMo合金材料信息
[LLM提取Agent]     ↻ 完善记录 1: 新增2字段, 合并0字段
```

## ❓ 常见问题

### Q: 提取不出来数据？
A: 
1. 检查论文是否已解析为 `full.md`
2. 使用 `gpt-4o` 模型（更准确）
3. 查看日志，确认是否有API错误

### Q: 字段太少？
A:
1. 增大 `CHUNK_SIZE` 到15000
2. 确认论文确实包含相关实验数据
3. 某些字段（如股骨柄、内衬）可能论文未涉及

### Q: 提取速度慢？
A:
1. 使用 `gpt-4o-mini` 模型
2. 减小 `CHUNK_SIZE`
3. 大论文需要更长时间（每个chunk约5-10秒）

### Q: API错误500？
A:
- 这是API提供商的临时问题
- 系统会自动跳过并继续处理其他chunks
- 不影响已提取的数据

## 📊 提取的28个字段

### 基本信息 (3个)
1. 数据标识
2. 应用部位
3. 产品所属专利号或文献

### 球头信息 (4个)
4. 球头基本信息
5. 球头-成分组成
6. 球头-物理性能
7. 球头-微观组织

### 内衬信息 (6个)
8-13. 内衬-基本信息/改性填料/成分组成/物理性能/复合材料性能/材料表征

### 股骨柄信息 (4个)
14-17. 股骨柄基本信息/成分组成/物理性能/微观组织

### 摩擦腐蚀实验 (7个)
18-24. 实验设置/润滑液组成/球头磨损/内衬磨损/球头腐蚀/内衬腐蚀/表面成分

### 微动腐蚀实验 (3个)
25-27. 实验设置/润滑液组成/腐蚀磨损结果

### 元数据 (2个)
28-29. dataid, paper_id（自动添加）

## 💡 最佳实践

1. **先测试再批量**: 用 `single` 命令测试几篇论文，确认效果满意后再 `batch`
2. **检查结果**: 提取后查看 `data/processed/extracted/` 下的JSON文件
3. **质量优先**: 使用 `gpt-4o` 模型以获得最佳质量
4. **合理预期**: 平均每篇论文8-10个非空字段是正常的（很多论文不包含所有字段）

## 📞 需要帮助？

查看详细文档：
- `README.md` - 系统概述
- `EXTRACTION_SUCCESS_REPORT.md` - 测试报告
- `prompts/prompt.md` - 提取prompt详情
- `docs/` - 更多文档

系统已经过真实论文测试，可以放心使用！🎉
