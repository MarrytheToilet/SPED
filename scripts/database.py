#!/usr/bin/env python3
"""
æ•°æ®åº“ç®¡ç†å‘½ä»¤è¡Œå·¥å…·
"""
import sys
from pathlib import Path
from loguru import logger

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))  # scripts/ -> sped/

from src.database.db_manager import DatabaseManager
from src.database.csv_exporter import CSVExporter, export_all_formats


def show_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    print("\n" + "="*80)
    print("æ•°æ®åº“ç®¡ç†å·¥å…·")
    print("="*80)
    print("\n1. ğŸ“Š æŸ¥çœ‹æ•°æ®åº“ç»Ÿè®¡")
    print("2. ğŸ“¥ ä»JSONæ–‡ä»¶å¯¼å…¥æ•°æ®")
    print("3. ğŸ“¥ æ‰¹é‡å¯¼å…¥extractedç›®å½•çš„æ‰€æœ‰JSON")
    print("4. ğŸ“¤ å¯¼å‡ºCSVï¼ˆå®Œæ•´æ•°æ®-å±•å¼€JSONï¼‰â­ æ¨è")
    print("5. ğŸ“¤ å¯¼å‡ºCSVï¼ˆå®Œæ•´æ•°æ®-ä¿ç•™JSONï¼‰")
    print("6. ğŸ“¤ å¯¼å‡ºCSVï¼ˆæ•°æ®æ‘˜è¦ï¼‰")
    print("7. ğŸ“¤ å¯¼å‡ºæ‰€æœ‰æ ¼å¼ï¼ˆå±•å¼€JSONï¼‰â­")
    print("8. ğŸ” æŸ¥è¯¢è®ºæ–‡æ•°æ®")
    print("9. ğŸ—‘ï¸  åˆ é™¤è®ºæ–‡æ•°æ®")
    print("10. âš ï¸  æ¸…ç©ºæ‰€æœ‰æ•°æ®")
    print("0. ğŸšª é€€å‡º")
    print("="*80)


def view_statistics(db: DatabaseManager):
    """æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*80)
    print("æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("="*80)
    
    stats = db.get_statistics()
    
    print(f"\nğŸ“Š æ€»è®°å½•æ•°: {stats.get('total_records', 0)}")
    print(f"ğŸ“ æœ‰åº”ç”¨éƒ¨ä½çš„è®°å½•: {stats.get('with_application', 0)}")
    print(f"ğŸ“„ ä¸åŒè®ºæ–‡æ•°: {stats.get('unique_papers', 0)}")
    print(f"ğŸ• æœ€è¿‘æ›´æ–°: {stats.get('last_updated', 'N/A')}")
    
    size_mb = stats.get('database_size', 0) / 1024 / 1024
    print(f"ğŸ’¾ æ•°æ®åº“å¤§å°: {size_mb:.2f} MB")
    
    print("\n" + "="*80)


def import_from_json(db: DatabaseManager):
    """ä»JSONæ–‡ä»¶å¯¼å…¥"""
    print("\nè¯·è¾“å…¥JSONæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹æˆ–ç»å¯¹è·¯å¾„ï¼‰:")
    file_path = input("è·¯å¾„: ").strip()
    
    if not file_path:
        print("âŒ è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    json_file = Path(file_path)
    
    if not json_file.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return
    
    print(f"\nğŸ“¥ å¼€å§‹å¯¼å…¥: {json_file.name}")
    result = db.insert_from_json(json_file)
    
    print(f"\nâœ… å¯¼å…¥å®Œæˆ:")
    print(f"   - æˆåŠŸ: {result['success']} æ¡")
    print(f"   - å¤±è´¥: {result['failed']} æ¡")


def batch_import_extracted(db: DatabaseManager):
    """æ‰¹é‡å¯¼å…¥extractedç›®å½•"""
    extracted_dir = Path("data/processed/extracted")
    
    if not extracted_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {extracted_dir}")
        return
    
    json_files = list(extracted_dir.glob("*.json"))
    
    if not json_files:
        print(f"âŒ ç›®å½•ä¸­æ²¡æœ‰JSONæ–‡ä»¶: {extracted_dir}")
        return
    
    print(f"\nğŸ“¥ æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    print("æ˜¯å¦ç»§ç»­å¯¼å…¥ï¼Ÿ(y/n): ", end='')
    
    if input().lower() != 'y':
        print("å–æ¶ˆå¯¼å…¥")
        return
    
    print("\nå¼€å§‹æ‰¹é‡å¯¼å…¥...")
    total_success = 0
    total_failed = 0
    
    for i, json_file in enumerate(json_files, 1):
        print(f"\n[{i}/{len(json_files)}] {json_file.name}")
        result = db.insert_from_json(json_file)
        total_success += result['success']
        total_failed += result['failed']
        print(f"  âœ… æˆåŠŸ: {result['success']}, âŒ å¤±è´¥: {result['failed']}")
    
    print("\n" + "="*80)
    print("æ‰¹é‡å¯¼å…¥å®Œæˆ")
    print("="*80)
    print(f"æ€»è®¡æˆåŠŸ: {total_success} æ¡")
    print(f"æ€»è®¡å¤±è´¥: {total_failed} æ¡")
    print("="*80)


def export_csv_expanded(db: DatabaseManager):
    """å¯¼å‡ºCSVï¼ˆå±•å¼€JSONï¼‰"""
    exporter = CSVExporter(db)
    
    output_dir = Path("data/exports")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"full_data_expanded_{timestamp}.csv"
    
    print(f"\nğŸ“¤ å¯¼å‡ºåˆ°: {output_file}")
    print("â³ æ­£åœ¨å±•å¼€JSONå­—æ®µ...")
    
    if exporter.export_all(output_file, flatten_json=False, expand_json=True):
        print(f"âœ… å¯¼å‡ºæˆåŠŸ!")
        print(f"æ–‡ä»¶: {output_file.absolute()}")
        
        # æ˜¾ç¤ºç»Ÿè®¡
        import csv
        with open(output_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames
            records = list(reader)
        print(f"ğŸ“Š å¯¼å‡ºäº† {len(records)} æ¡è®°å½•, {len(headers)} ä¸ªå­—æ®µ")
    else:
        print("âŒ å¯¼å‡ºå¤±è´¥")


def export_csv_raw(db: DatabaseManager):
    """å¯¼å‡ºCSVï¼ˆä¿ç•™JSONï¼‰"""
    exporter = CSVExporter(db)
    
    output_dir = Path("data/exports")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"full_data_raw_{timestamp}.csv"
    
    print(f"\nğŸ“¤ å¯¼å‡ºåˆ°: {output_file}")
    
    if exporter.export_all(output_file, flatten_json=False, expand_json=False):
        print(f"âœ… å¯¼å‡ºæˆåŠŸ!")
        print(f"æ–‡ä»¶: {output_file.absolute()}")
    else:
        print("âŒ å¯¼å‡ºå¤±è´¥")


def export_csv_summary(db: DatabaseManager):
    """å¯¼å‡ºCSVæ‘˜è¦"""
    exporter = CSVExporter(db)
    
    output_dir = Path("data/exports")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"summary_{timestamp}.csv"
    
    print(f"\nğŸ“¤ å¯¼å‡ºæ‘˜è¦åˆ°: {output_file}")
    
    if exporter.export_summary(output_file):
        print(f"âœ… å¯¼å‡ºæˆåŠŸ!")
        print(f"æ–‡ä»¶: {output_file.absolute()}")
    else:
        print("âŒ å¯¼å‡ºå¤±è´¥")


def export_all_csv_formats(db: DatabaseManager):
    """å¯¼å‡ºæ‰€æœ‰æ ¼å¼CSV"""
    output_dir = Path("data/exports")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“¤ å¯¼å‡ºæ‰€æœ‰æ ¼å¼åˆ°: {output_dir}")
    print("â³ å¼€å§‹å¯¼å‡º...")
    
    export_all_formats(output_dir, expand_json=True)
    
    print(f"\nâœ… æ‰€æœ‰æ ¼å¼å¯¼å‡ºå®Œæˆ!")
    print(f"ç›®å½•: {output_dir.absolute()}")
    
    output_dir = Path("data/exports")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"key_fields_{timestamp}.csv"
    
    print(f"\nğŸ“¤ å¯¼å‡ºå…³é”®å­—æ®µåˆ°: {output_file}")
    print(f"å­—æ®µæ•°: {len(key_fields)}")
    
    if exporter.export_custom_fields(output_file, key_fields, filter_empty=True):
        print(f"âœ… å¯¼å‡ºæˆåŠŸ!")
        print(f"æ–‡ä»¶: {output_file.absolute()}")
    else:
        print("âŒ å¯¼å‡ºå¤±è´¥")


def query_paper_data(db: DatabaseManager):
    """æŸ¥è¯¢è®ºæ–‡æ•°æ®"""
    print("\nè¯·è¾“å…¥è®ºæ–‡IDï¼ˆpaper_idï¼‰:")
    paper_id = input("Paper ID: ").strip()
    
    if not paper_id:
        print("âŒ Paper IDä¸èƒ½ä¸ºç©º")
        return
    
    records = db.query_by_paper_id(paper_id)
    
    if not records:
        print(f"âŒ æœªæ‰¾åˆ°è®ºæ–‡ '{paper_id}' çš„æ•°æ®")
        return
    
    print(f"\næ‰¾åˆ° {len(records)} æ¡è®°å½•:\n")
    
    for i, record in enumerate(records, 1):
        non_null = sum(1 for v in record.values() if v and v != '' and v != 'null')
        print(f"{i}. DataID: {record.get('dataid', 'N/A')}")
        print(f"   æ•°æ®æ ‡è¯†: {record.get('æ•°æ®æ ‡è¯†', 'N/A')}")
        print(f"   åº”ç”¨éƒ¨ä½: {record.get('åº”ç”¨éƒ¨ä½', 'N/A')}")
        print(f"   éç©ºå­—æ®µ: {non_null}/30")
        print()


def delete_paper_data(db: DatabaseManager):
    """åˆ é™¤è®ºæ–‡æ•°æ®"""
    print("\nâš ï¸  è­¦å‘Š: æ­¤æ“ä½œå°†åˆ é™¤æŒ‡å®šè®ºæ–‡çš„æ‰€æœ‰æ•°æ®!")
    print("\nè¯·è¾“å…¥è®ºæ–‡IDï¼ˆpaper_idï¼‰:")
    paper_id = input("Paper ID: ").strip()
    
    if not paper_id:
        print("âŒ Paper IDä¸èƒ½ä¸ºç©º")
        return
    
    # å…ˆæŸ¥è¯¢
    records = db.query_by_paper_id(paper_id)
    
    if not records:
        print(f"âŒ æœªæ‰¾åˆ°è®ºæ–‡ '{paper_id}' çš„æ•°æ®")
        return
    
    print(f"\næ‰¾åˆ° {len(records)} æ¡è®°å½•")
    print(f"ç¡®è®¤åˆ é™¤ï¼Ÿ(y/n): ", end='')
    
    if input().lower() != 'y':
        print("å–æ¶ˆåˆ é™¤")
        return
    
    deleted = db.delete_by_paper_id(paper_id)
    print(f"\nâœ… å·²åˆ é™¤ {deleted} æ¡è®°å½•")


def clear_all_data(db: DatabaseManager):
    """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
    print("\nâš ï¸âš ï¸âš ï¸  è­¦å‘Š: æ­¤æ“ä½œå°†æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼âš ï¸âš ï¸âš ï¸")
    print("è¯·è¾“å…¥ 'DELETE ALL' ç¡®è®¤:")
    
    confirm = input("ç¡®è®¤: ").strip()
    
    if confirm != 'DELETE ALL':
        print("å–æ¶ˆæ“ä½œ")
        return
    
    print("\nå†æ¬¡ç¡®è®¤ï¼Œæ˜¯å¦æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼Ÿ(yes/no): ", end='')
    
    if input().lower() != 'yes':
        print("å–æ¶ˆæ“ä½œ")
        return
    
    if db.clear_all():
        print("\nâœ… æ‰€æœ‰æ•°æ®å·²æ¸…ç©º")
    else:
        print("\nâŒ æ¸…ç©ºå¤±è´¥")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(sys.stderr, level="WARNING")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = DatabaseManager()
    
    while True:
        show_menu()
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (0-10): ").strip()
        
        if choice == '0':
            print("\nå†è§ï¼ğŸ‘‹")
            break
        elif choice == '1':
            view_statistics(db)
        elif choice == '2':
            import_from_json(db)
        elif choice == '3':
            batch_import_extracted(db)
        elif choice == '4':
            export_csv_expanded(db)
        elif choice == '5':
            export_csv_raw(db)
        elif choice == '6':
            export_csv_summary(db)
        elif choice == '7':
            export_all_csv_formats(db)
        elif choice == '8':
            query_paper_data(db)
        elif choice == '9':
            delete_paper_data(db)
        elif choice == '10':
            clear_all_data(db)
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
        
        input("\næŒ‰å›è½¦ç»§ç»­...")


if __name__ == "__main__":
    main()
